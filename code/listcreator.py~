import sys
import os
import re
import random
from decimal import *
from math import *

def create_aggregated_web(fillist,directory):

  predpreydict={}
  specieslist=set()
  for fil in fillist:
    rowdict={}

    webfile = directory+'/'+fil+'.csv'
    f=open(webfile,'r')
    for line in f:
      newline=line.split('\n')[0] #Trims off extraneous newline
      items=newline.split(',')
      if '' not in items[1:]:
        rowdict[items[0]]=items[1:]
    f.close()

    for row in rowdict:
      for item in rowdict[row]:
        try:
          item = int(item)
        except:
          predators = row

    for item in rowdict[predators]:
      position = rowdict[predators].index(item)
      specieslist.add(item)
      preylist=[]
      for row in rowdict:
        specieslist.add(row)
        if row != predators:
          try:
            if rowdict[row][position]!='0':
              preylist.append(row)
          except:
            print fil, row
            print rowdict[predators][position], position
          
      predpreydict[item]=preylist

  numberdict={}
  i = 1
  for species in specieslist:
    numberdict[species]=i
    i=i+1

  webname=re.findall(r'WEB(\d+)',webfile)[0]

  g=open('Food-web-database/pred-prey-lists-to-use/WEB'+str(1000+int(webname)),'w')
  for pred in rowdict[predators]:
    for prey in predpreydict[pred]:
      g.write(str(numberdict[pred])+'\t'+str(numberdict[prey])+'\n')
  g.close()



def create_predprey_list(webfile):
  rowdict={}
  goodrowdict={}

  f=open(webfile,'r')
  for line in f:
    newline=line.split('\n')[0] #Trims off extraneous newline
    items=newline.split(',')
    if '' not in items[1:]:
      rowdict[items[0]]=items[1:]
  f.close()

  for row in rowdict:
    for item in rowdict[row]:
      try:
        item = int(item)
      except:
        predators = row
  
  predpreydict={}
  specieslist=set()

  for item in rowdict[predators]:
    specieslist.add(item)
    preylist=[]
    position = rowdict[predators].index(item)
    for row in rowdict:
      specieslist.add(row)
      if row != predators:
        if rowdict[row][position]!='0':
          preylist.append(row)
    predpreydict[item]=preylist

  numberdict={}
  i = 1
  for species in specieslist:
    numberdict[species]=i
    i=i+1

  webname=re.findall(r'(WEB\d+)',webfile)[0]

  g=open('Food-web-database/pred-prey-lists-to-use/'+webname,'w')
  for pred in rowdict[predators]:
    for prey in predpreydict[pred]:
      g.write(str(numberdict[pred])+'\t'+str(numberdict[prey])+'\n')
  g.close()


def weblister(directory):

  filelist=os.listdir(directory)

  Ruzicka=['WEB320','WEB321','WEB322','WEB323','WEB324']
  Fryer=['WEB38','WEB39','WEB204']
  Dexter=['WEB110','WEB111','WEB112','WEB113']
  Alcorlo_Pinol=['WEB334','WEB336']
  Alcorlo_Muerta=['WEB335','WEB337']
  Closs = ['WEB297','WEB298','WEB299','WEB300','WEB301','WEB302','WEB303','WEB304','WEB305','WEB306','WEB307','WEB308']
  Parker_spring = ['WEB273','WEB275']
  Parker_stream = ['WEB274','WEB276']
  Kelleway_Gingham=['WEB327','WEB330']
  Kelleway_Gwydir=['WEB328','WEB331']
  Yanez=['WEB44','WEB57']

  aggregators=[Ruzicka,Fryer,Dexter,Alcorlo_Muerta,Alcorlo_Pinol,Closs,Parker_stream,Parker_spring,Kelleway_Gwydir,Kelleway_Gingham]
  agglist=Ruzicka+Fryer+Dexter+Alcorlo_Pinol+Alcorlo_Muerta+Closs+Parker_spring+Parker_stream+Kelleway_Gingham+Kelleway_Gwydir

  for fil in filelist:
    if fil in agglist:
      pass
    else:
      webfile = directory+'/'+fil+'.csv'
      #try:
      create_predprey_list(webfile)
      #except:
      #  print fil
      #  pass

  for fillist in aggregators:
    create_aggregated_web(fillist,directory)


def main():
  
  directory = 'Food-web-database/csv_webs'

  weblister(directory)

if __name__ == '__main__':
  main()
